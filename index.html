
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Nanum Gothic', Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  heading {
    font-family: 'Nanum Gothic', Helvetica, sans-serif;
    font-size: 19px;
    font-weight: 1000
  }
  strong {
    font-family: 'Nanum Gothic', Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 800
  }
  sectionheading {
    font-family: 'Nanum Gothic', Helvetica, sans-serif;
    font-size: 22px;
    font-weight: 600
  }
  </style>
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Daniele Reda</title>
  <meta name="Daniele Reda's Homepage" http-equiv="Content-Type" content="Daniele Reda's Homepage">
  <link href="https://fonts.googleapis.com/css?family=Nanum+Gothic" rel="stylesheet" type="text/css">

  <!-- Start : Google Analytics Code -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-105843563-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-105843563-1');
  </script>
  <!-- End : Google Analytics Code -->
</head>

<body>
<table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center"><font size="7">Daniele Reda</font><br>
    <b>Email</b>: redad dot 93 at gmail dot com
  </p>

  <tr>
    <td width="67%" valign="middle" align="justify">
    <p>I'm a reinforcement learning researcher at <a href="http://wayve.ai/">Wayve</a> where we apply machine learning to robotics control to make self-driving cars.</p>

    <p>My research interests in AI include deep reinforcement learning and deep learning for self-improving models with minimum to no supervision.</p>

    <p>I completed my B.Sc. and my M.Sc. at <a href="https://www.polito.it/en">Polytechnic University of Turin</a>. During this period I was granted a double degree scholarship to study for one year at Telecom ParisTech - <a href="http://www.eurecom.fr/en">Eurecom Research Center</a>. I was a visiting researcher at <a href="http://bair.berkeley.edu">Berkeley AI Research</a> at UC Berkeley for 6 months where I did research for my master thesis with professor <a href="https://people.eecs.berkeley.edu/~bajcsy/">Ruzena Bajcsy</a>.</p>

    <p align=center>
    <a href="reda_cv.pdf">CV</a> |
    <a href="https://scholar.google.com/citations?user=fwVWk9UAAAAJ">Google Scholar</a> |
    <a href="https://github.com/rdednl">Github</a> |
    <a href="https://linkedin.com/in/rdednl"> LinkedIn </a> |
    <a href="https://twitter.com/rdednl"> Twitter </a>
    </p>
    </td>

    <td width="33%"><a href="reda.jpg"><img src="reda.jpg" width="90%"></a></td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td><sectionheading>Publications</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

  <tr>
    <td width="100%" valign="top">
      <heading>Learning to drive in a day</heading></a><br>
      Alex Kendall, Jeffrey Hawke, David Janz, Przemyslaw Mazur, <strong>Daniele Reda</strong>, John-Mark Allen, Vinh-Dieu Lam, Alex Bewley, Amar Shah<br>
      </p>

      <a href="https://arxiv.org/abs/1807.00412">arXiv</a> |
      <a href="https://wayve.ai/blog/learning-to-drive-in-a-day-with-reinforcement-learning">blog post</a> |
      <a href="https://arxiv.org/pdf/1807.00412.pdf">pdf</a>
      <br>

      <p align="justify"> Abstract: We demonstrate the first application of deep reinforcement learning to autonomous driving. From randomly initialised parameters, our model is able to learn a policy for lane following in a handful of training episodes using a single monocular image as input. We provide a general and easy to obtain reward: the distance travelled by the vehicle without the safety driver taking control. We use a continuous, model-free deep reinforcement learning algorithm, with all exploration and optimisation performed on-vehicle. This demonstrates a new framework for autonomous driving which moves away from reliance on defined logical rules, mapping, and direct supervision. We discuss the challenges and opportunities to scale this approach to a broader range of autonomous driving tasks.</i></p> 
    </td>
  </tr>

</table>

<table width="100%" align="center" border="0" cellpadding="20">
  <tr><td>
    <sectionheading>Outreach</sectionheading>
    <ul>
    <li> I enjoy taking pictures and sharing them on <a href="http://www.instagram.com/rdednl">Instagram</a>.</li>
    <li> I (try to) <a href="http://rdednl.com/blog">blog</a> on my interests. Mostly mountain climbing/hiking and AI.</li>
    </ul>
  </td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr><td><br><p align="right"><font size="2">
    Template: <a href="http://www.cs.berkeley.edu/~barron/">this</a> and <a href="https://people.eecs.berkeley.edu/~pathak/">this</a>
    </font></p></td></tr>
</table>

  </td></tr>
</table>

</body>
</html>
